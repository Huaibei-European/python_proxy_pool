"""
è¿™æ˜¯è·å–å…è´¹ä»£ç†çš„æ¨¡å—
"""
"""
ç›®æ ‡ç½‘å€ï¼š
å¿«ä»£ç†ï¼šhttps://www.kuaidaili.com/free/
äº‘ä»£ç†ï¼šhttp://www.ip3366.net/
89ä»£ç†ï¼šhttps://www.89ip.cn/
"""

import requests
import re

headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36'}

re_pattern = re.compile('.*?(\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}).*?(\d{1,5}).*?', re.S)


def spider_kuai_proxy():
    """æŠ“å–å¿«ä»£ç†çš„ipåœ°å€å’Œç«¯å£å·"""
    for page in range(1, 6):
        html_data = requests.get(url=f'http://www.ip3366.net/?stype=1&page={page}', headers=headers).text
        print('å¿«ä»£ç†:', f'http://www.ip3366.net/?stype=1&page={page}')
        ip = re.findall(re_pattern, html_data)
        # print(ip)
        # å°†ipä»åˆ—è¡¨ä¸­çš„å…ƒç»„ä¸­éƒ½æå–å‡ºæ¥
        for ip, port in ip:
            yield ip + ':' + port


def spider_yun_proxy():
    """æŠ“å–äº‘ä»£ç†çš„ipåœ°å€å’Œç«¯å£å·"""
    for page in range(1, 6):
        html_data = requests.get(url=f'http://www.ip3366.net/?stype=1&page={page}', headers=headers).text
        print('äº‘ä»£ç†:', f'http://www.ip3366.net/?stype=1&page={page}')
        ip = re.findall(re_pattern, html_data)
        # print(ip)
        # å°†ipä»åˆ—è¡¨ä¸­çš„å…ƒç»„ä¸­éƒ½æå–å‡ºæ¥
        for ip, port in ip:
            yield ip + ':' + port


def spider_89_proxy():
    """æŠ“å–89ä»£ç†çš„ipåœ°å€å’Œç«¯å£å·"""
    for page in range(1, 6):
        html_data = requests.get(url=f'https://www.89ip.cn/index_{page}.html', headers=headers).text
        print('89ä»£ç†:', f'https://www.89ip.cn/index_{page}.html')
        ip = re.findall(re_pattern, html_data)
        # print(ip)
        # å°†ipä»åˆ—è¡¨ä¸­çš„å…ƒç»„ä¸­éƒ½æå–å‡ºæ¥
        for ip, port in ip:
            yield ip + ':' + port


# for i in spider_kuai_proxy():
#     print(i)
# for i in spider_yun_proxy():
#     print(i)
# for i in spider_89_proxy():
#     print(i)

"""
è®©æ‰€æœ‰å‡½æ•°å¯¹è±¡ï¼Œä¾æ¬¡å»è¿è¡Œ
ğŸ¦†é¸­å­ğŸ¦†ç±»å‹
ä¸å…³å¿ƒå¯¹è±¡æ˜¯ä»€ä¹ˆç±»å‹ï¼Œåªå…³æ³¨å¯¹è±¡çš„è¡Œä¸ºã€‚
åœ¨è¿™é‡Œï¼Œä¸å…³æ³¨å‡½æ•°åç§°æ˜¯ä»€ä¹ˆç±»å‹ï¼Œå³ä¸ç®¡å®ƒæ˜¯ä¸æ˜¯å‡½æ•°ï¼Œæˆ‘åªå…³æ³¨ï¼ŒåŠ äº†æ‹¬å·ä¹‹åï¼Œå®ƒèƒ½å¤Ÿè¿è¡Œ
"""
get_proxy_func_list = [spider_kuai_proxy, spider_yun_proxy, spider_89_proxy]
# if __name__ == '__main__':
#     get_proxy_func_list = [spider_kuai_proxy, spider_yun_proxy, spider_89_proxy]
# for func in get_proxy_func_list:
#     proxies = func()
#     for proxy in proxies:
#         print(proxy)
# redis_client = RedisClient()
# redis_client.add(proxy)
